{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ce2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4585489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b365fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_215623) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_254805) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_257010) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_254845) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_253233) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_215297) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_216487) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_262359) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_214684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_254666) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_218297) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_261806) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_218742) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_262952) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_217879) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_217747) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_260234) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_254292) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_216313) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_217308) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_216445) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_218165) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_253786) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_256417) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_258069) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_252880) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_255219) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_215414) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_255864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_214801) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_261300) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_215875) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_261161) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_214295) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_264058) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_256457) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_260194) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_216069) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_257337) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_215665) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_218130) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_244127) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_216654) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_216104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_216278) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_214474) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_217343) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_264385) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_218583) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_217921) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_215491) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_256278) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_216027) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_216848) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_253746) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_215456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_258996) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_215262) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_217712) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_217670) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_258443) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb1_layer_call_and_return_conditional_losses_248195) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_256970) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_216522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_262220) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_216731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_254252) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_257516) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_254113) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_241574) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_255398) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_255358) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_218700) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_214253) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_255725) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_260608) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_218548) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_214878) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_263505) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_262399) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_216925) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_215010) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_216696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_217266) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_217134) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_261667) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_217099) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_259135) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_216236) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_214606) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_215832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_253607) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_260747) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_252701) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_217475) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_263326) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_258582) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_261846) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_255904) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_215910) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_257890) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_264564) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_262773) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_218374) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_215052) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_217057) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_214649) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_260055) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_259681) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_252840) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_264018) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_259175) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_214843) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_262912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_263879) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb1_layer_call_and_return_conditional_losses_250729) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_217956) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_218909) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_258622) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_214330) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_218506) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_264938) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_259641) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_215087) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_260787) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_256831) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_204708) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_217518) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_261340) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_218088) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_263465) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_214439) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_258029) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_253193) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_259502) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_217553) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_257476) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_216890) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_264524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_215219) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_218777) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_218339) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_215700) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"D:/Modelos/EfficientNet_B1_IMAGENET_IC_SCM3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92410b77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb1 (Functional)  (None, 1, 1, 1280)        6575239   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 5124      \n",
      "=================================================================\n",
      "Total params: 6,580,363\n",
      "Trainable params: 6,518,308\n",
      "Non-trainable params: 62,055\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffc904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75776, 32, 32, 3), (75776, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carrega os arrays de imagens e de classes\n",
    "train_X = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3.npy\")\n",
    "train_label = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataYOneHot_teste3.npy\")\n",
    "XSCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_GLCM.npy\")\n",
    "#dataX = np.load(\"Image Arrays/displasiaGeneratedDataX.npy\")\n",
    "#dataY = np.load(\"Image Arrays/displasiaGeneratedDataY.npy\")\n",
    "\n",
    "#shape dos arrays\n",
    "train_X.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d74f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9982845077856954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3867\n",
      "     Class 1       1.00      1.00      1.00      3755\n",
      "     Class 2       1.00      1.00      1.00      3686\n",
      "     Class 3       1.00      1.00      1.00      3848\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15156\n",
      "   macro avg       1.00      1.00      1.00     15156\n",
      "weighted avg       1.00      1.00      1.00     15156\n",
      " samples avg       1.00      1.00      1.00     15156\n",
      "\n",
      "Precision:   [0.99948307 0.99680426 0.99728703 0.99947998]\n",
      "Sensitivity: [1.         0.99680426 0.99728703 0.9989605 ]\n",
      "Specificity: [0.99982284 0.99894746 0.99912816 0.99982313]\n",
      "F1-score:    [0.99974147 0.99680426 0.99728703 0.99922017]\n",
      "Accuracy:    [0.99986804 0.99841647 0.99868039 0.99960412]\n",
      "\n",
      "[[0.99948307 1.         0.99982284 0.99974147 0.99986804]\n",
      " [0.99680426 0.99680426 0.99894746 0.99680426 0.99841647]\n",
      " [0.99728703 0.99728703 0.99912816 0.99728703 0.99868039]\n",
      " [0.99947998 0.9989605  0.99982313 0.99922017 0.99960412]]\n",
      "Accuracy: 0.9985483338832069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3761\n",
      "     Class 1       1.00      1.00      1.00      3776\n",
      "     Class 2       1.00      1.00      1.00      3819\n",
      "     Class 3       1.00      1.00      1.00      3799\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [0.9989373  0.99893815 0.99712569 0.9992099 ]\n",
      "Sensitivity: [0.99973411 0.9965572  0.99921445 0.99868386]\n",
      "Specificity: [0.99964894 0.99964848 0.99902964 0.99973582]\n",
      "F1-score:    [0.99933555 0.99774625 0.99816898 0.99894681]\n",
      "Accuracy:    [0.99967008 0.99887826 0.99907621 0.99947212]\n",
      "\n",
      "[[0.9989373  0.99973411 0.99964894 0.99933555 0.99967008]\n",
      " [0.99893815 0.9965572  0.99964848 0.99774625 0.99887826]\n",
      " [0.99712569 0.99921445 0.99902964 0.99816898 0.99907621]\n",
      " [0.9992099  0.99868386 0.99973582 0.99894681 0.99947212]]\n",
      "Accuracy: 0.998020455295282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3802\n",
      "     Class 1       1.00      1.00      1.00      3797\n",
      "     Class 2       1.00      1.00      1.00      3741\n",
      "     Class 3       1.00      1.00      1.00      3815\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [0.9994741  0.99631482 0.99705882 0.99921322]\n",
      "Sensitivity: [0.99973698 0.99683961 0.9967923  0.99868938]\n",
      "Specificity: [0.99982384 0.99876739 0.99903627 0.99973545]\n",
      "F1-score:    [0.99960552 0.99657715 0.99692554 0.99895123]\n",
      "Accuracy:    [0.99980205 0.99828439 0.99848235 0.99947212]\n",
      "\n",
      "[[0.9994741  0.99973698 0.99982384 0.99960552 0.99980205]\n",
      " [0.99631482 0.99683961 0.99876739 0.99657715 0.99828439]\n",
      " [0.99705882 0.9967923  0.99903627 0.99692554 0.99848235]\n",
      " [0.99921322 0.99868938 0.99973545 0.99895123 0.99947212]]\n",
      "Accuracy: 0.9978884856483009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3655\n",
      "     Class 1       1.00      1.00      1.00      3841\n",
      "     Class 2       1.00      1.00      1.00      3840\n",
      "     Class 3       1.00      1.00      1.00      3819\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [0.99917943 0.99687419 0.99635891 0.99921363]\n",
      "Sensitivity: [0.9994528  0.99635512 0.99765625 0.99816706]\n",
      "Specificity: [0.99973913 0.99893937 0.9987627  0.99973536]\n",
      "F1-score:    [0.9993161  0.99661458 0.99700716 0.99869007]\n",
      "Accuracy:    [0.99967008 0.99828439 0.99848235 0.99934015]\n",
      "\n",
      "[[0.99917943 0.9994528  0.99973913 0.9993161  0.99967008]\n",
      " [0.99687419 0.99635512 0.99893937 0.99661458 0.99828439]\n",
      " [0.99635891 0.99765625 0.9987627  0.99700716 0.99848235]\n",
      " [0.99921363 0.99816706 0.99973536 0.99869007 0.99934015]]\n",
      "Accuracy: 0.9982184097657538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3859\n",
      "     Class 1       1.00      1.00      1.00      3775\n",
      "     Class 2       1.00      1.00      1.00      3858\n",
      "     Class 3       1.00      1.00      1.00      3663\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [0.999482   0.99655811 0.99844358 0.99863463]\n",
      "Sensitivity: [1.         0.99708609 0.99766719 0.998362  ]\n",
      "Specificity: [0.99982295 0.99885764 0.99946889 0.99956491]\n",
      "F1-score:    [0.99974093 0.99682203 0.99805523 0.99849829]\n",
      "Accuracy:    [0.99986803 0.99841636 0.99901023 0.99927417]\n",
      "\n",
      "[[0.999482   1.         0.99982295 0.99974093 0.99986803]\n",
      " [0.99655811 0.99708609 0.99885764 0.99682203 0.99841636]\n",
      " [0.99844358 0.99766719 0.99946889 0.99805523 0.99901023]\n",
      " [0.99863463 0.998362   0.99956491 0.99849829 0.99927417]]\n",
      "99.82% (+/- 0.02%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "\n",
    "mean = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "std = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "for train, test in kfold.split (train_X, train_label):\n",
    "\n",
    "    intermediate_layer_model = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output = intermediate_layer_model.predict(train_X[train])\n",
    "\n",
    "    newArr = np.append(intermediate_output, XSCM[train] , axis=1)\n",
    "\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    #train_labels2=train_labels[:49984]\n",
    "    clf.fit(newArr,train_label[train])\n",
    "\n",
    "    intermediate_layer_model_2 = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output_2 = intermediate_layer_model_2.predict(train_X[test])\n",
    "\n",
    "    newArr_test = np.append(intermediate_output_2, XSCM[test] , axis=1)\n",
    "\n",
    "    y_pred=clf.predict(newArr_test)\n",
    "\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(train_label[test], y_pred))\n",
    "    cvscores.append(metrics.accuracy_score(train_label[test], y_pred)*100)\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "\n",
    "    predicted_classes = y_pred\n",
    "\n",
    "    predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "\n",
    "    predicted_classes = to_categorical(predicted_classes)\n",
    "\n",
    "    \n",
    "    num_classes = 4\n",
    "    from sklearn.metrics import classification_report\n",
    "    target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "    print(classification_report(train_label[test], predicted_classes, target_names=target_names))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    #converte os arrays de classe de one-hot para númerico\n",
    "    test_label_aux = np.argmax(train_label[test], axis=1)\n",
    "    predicted_classes = np.argmax(predicted_classes, axis=1)\n",
    "\n",
    "    #gera a matriz de confusão a partir da predição feita\n",
    "    cm = confusion_matrix(test_label_aux, predicted_classes)\n",
    "\n",
    "    #gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "    #gera a sensitividade, especificidade, acurácia e precisão\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision   = tp / (tp + fp)\n",
    "    f1_score = 2/((1/precision)+(1/sensitivity))\n",
    "\n",
    "    #mostra os resultados\n",
    "    print(\"Precision:  \", precision)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"F1-score:   \", f1_score)\n",
    "    print(\"Accuracy:   \", accuracy)\n",
    "    \n",
    "    x = []\n",
    "    x.append(precision)\n",
    "    x.append(sensitivity)\n",
    "    x.append(specificity)\n",
    "    x.append(f1_score)\n",
    "    x.append(accuracy)\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    x = x.transpose()\n",
    "    print()\n",
    "    print(x)\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            mean[i][j].append(x[i][j])\n",
    "            std[i][j].append(x[i][j])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores),np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dfad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99931118 0.99978478 0.99977154 0.99954791 0.99977565]\n",
      "[0.99709791 0.99672846 0.99903207 0.99691286 0.99845598]\n",
      "[0.99725481 0.99772344 0.99908513 0.99748879 0.99874631]\n",
      "[0.99915027 0.99857256 0.99971894 0.99886132 0.99943254]\n",
      "\n",
      "[2.20187133e-04 2.03813158e-04 6.94122670e-05 1.88082807e-04\n",
      " 8.95079668e-05]\n",
      "[0.000941   0.00025088 0.00031502 0.00042808 0.00021924]\n",
      "[0.00067408 0.00081096 0.0002274  0.00052411 0.00025384]\n",
      "[2.77895676e-04 2.77596835e-04 8.41513824e-05 2.47096114e-04\n",
      " 1.15056262e-04]\n"
     ]
    }
   ],
   "source": [
    "mean = np.asarray(mean)\n",
    "std = np.asarray(std)\n",
    "for i in mean:\n",
    "    print(np.mean(i,axis=1))\n",
    "print()\n",
    "for i in std:\n",
    "    print(np.std(i,axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
