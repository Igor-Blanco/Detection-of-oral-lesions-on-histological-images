{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ce2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4585489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b365fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"D:/Modelos/ResNet50_IC_copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92410b77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 24,638,852\n",
      "Trainable params: 24,585,732\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffc904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75776, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((75776, 32, 32, 3), (75776, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carrega os arrays de imagens e de classes\n",
    "train_X = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3.npy\")\n",
    "train_label = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataYOneHot_teste3.npy\")\n",
    "XSCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_GLCM.npy\")\n",
    "#XGLCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_GLCM.npy\")\n",
    "#dataX = np.load(\"Image Arrays/displasiaGeneratedDataX.npy\")\n",
    "#dataY = np.load(\"Image Arrays/displasiaGeneratedDataY.npy\")\n",
    "\n",
    "#XSCM = np.append(XSCM,XGLCM,axis=1)\n",
    "\n",
    "print(XSCM.shape)\n",
    "\n",
    "#shape dos arrays\n",
    "#train_X.shape, train_label.shape\n",
    "#shape dos arrays\n",
    "train_X.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8858e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X, test_X, train_label, test_label = train_test_split(X, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_label, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X.shape, train_label.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038f4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X_SCM, test_X_SCM, train_label_SCM, test_label_SCM = train_test_split(XSCM, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X_SCM, valid_X_SCM, train_label_SCM, valid_label_SCM = train_test_split(train_X_SCM, train_label_SCM, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X_SCM.shape, train_label_SCM.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X_SCM.shape, test_label_SCM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d74f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95460543679071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.99      0.96      3867\n",
      "     Class 1       0.95      0.94      0.94      3755\n",
      "     Class 2       0.97      0.94      0.95      3686\n",
      "     Class 3       0.99      0.95      0.97      3848\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     15156\n",
      "   macro avg       0.96      0.96      0.96     15156\n",
      "weighted avg       0.96      0.96      0.96     15156\n",
      " samples avg       0.96      0.96      0.96     15156\n",
      "\n",
      "Precision:   [0.92864054 0.94563471 0.96844457 0.98624224]\n",
      "Sensitivity: [0.99275924 0.94034621 0.9408573  0.95010395]\n",
      "Specificity: [0.97386837 0.98219454 0.99014821 0.99548992]\n",
      "F1-score:    [0.95963005 0.94298304 0.95445163 0.96783587]\n",
      "Accuracy:    [0.97868831 0.97182634 0.97816046 0.98396675]\n",
      "\n",
      "[[0.92864054 0.99275924 0.97386837 0.95963005 0.97868831]\n",
      " [0.94563471 0.94034621 0.98219454 0.94298304 0.97182634]\n",
      " [0.96844457 0.9408573  0.99014821 0.95445163 0.97816046]\n",
      " [0.98624224 0.95010395 0.99548992 0.96783587 0.98396675]]\n",
      "Accuracy: 0.9561200923787528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.99      0.96      3761\n",
      "     Class 1       0.95      0.95      0.95      3776\n",
      "     Class 2       0.97      0.94      0.96      3819\n",
      "     Class 3       0.98      0.95      0.97      3799\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     15155\n",
      "   macro avg       0.96      0.96      0.96     15155\n",
      "weighted avg       0.96      0.96      0.96     15155\n",
      " samples avg       0.96      0.96      0.96     15155\n",
      "\n",
      "Precision:   [0.92880259 0.94745223 0.97449118 0.98453189]\n",
      "Sensitivity: [0.9920234  0.94544492 0.94029851 0.95498815]\n",
      "Specificity: [0.97489907 0.98259953 0.99170783 0.99498063]\n",
      "F1-score:    [0.95937259 0.94644751 0.95708955 0.96953501]\n",
      "Accuracy:    [0.9791488  0.97334213 0.97875289 0.98495546]\n",
      "\n",
      "[[0.92880259 0.9920234  0.97489907 0.95937259 0.9791488 ]\n",
      " [0.94745223 0.94544492 0.98259953 0.94644751 0.97334213]\n",
      " [0.97449118 0.94029851 0.99170783 0.95708955 0.97875289]\n",
      " [0.98453189 0.95498815 0.99498063 0.96953501 0.98495546]]\n",
      "Accuracy: 0.9522269877928077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.99      0.96      3802\n",
      "     Class 1       0.94      0.94      0.94      3797\n",
      "     Class 2       0.97      0.93      0.95      3741\n",
      "     Class 3       0.98      0.96      0.97      3815\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     15155\n",
      "   macro avg       0.96      0.95      0.95     15155\n",
      "weighted avg       0.96      0.95      0.95     15155\n",
      " samples avg       0.95      0.95      0.95     15155\n",
      "\n",
      "Precision:   [0.92783251 0.94109878 0.96919234 0.98354021]\n",
      "Sensitivity: [0.99079432 0.9383724  0.93344026 0.95543906]\n",
      "Specificity: [0.97419184 0.98036626 0.9902751  0.99462081]\n",
      "F1-score:    [0.95828034 0.93973361 0.95098039 0.969286  ]\n",
      "Accuracy:    [0.97835698 0.96984494 0.97624546 0.98475751]\n",
      "\n",
      "[[0.92783251 0.99079432 0.97419184 0.95828034 0.97835698]\n",
      " [0.94109878 0.9383724  0.98036626 0.93973361 0.96984494]\n",
      " [0.96919234 0.93344026 0.9902751  0.95098039 0.97624546]\n",
      " [0.98354021 0.95543906 0.99462081 0.969286   0.98475751]]\n",
      "Accuracy: 0.9526888815572419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.99      0.95      3655\n",
      "     Class 1       0.94      0.94      0.94      3841\n",
      "     Class 2       0.97      0.93      0.95      3840\n",
      "     Class 3       0.99      0.95      0.97      3819\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     15155\n",
      "   macro avg       0.95      0.95      0.95     15155\n",
      "weighted avg       0.96      0.95      0.95     15155\n",
      " samples avg       0.95      0.95      0.95     15155\n",
      "\n",
      "Precision:   [0.91895325 0.94254375 0.96973791 0.98807265]\n",
      "Sensitivity: [0.98960328 0.93959906 0.93463542 0.95443833]\n",
      "Specificity: [0.97226087 0.98055506 0.99010163 0.99611856]\n",
      "F1-score:    [0.95297062 0.9410691  0.95186315 0.9709643 ]\n",
      "Accuracy:    [0.97644342 0.97017486 0.97604751 0.98561531]\n",
      "\n",
      "[[0.91895325 0.98960328 0.97226087 0.95297062 0.97644342]\n",
      " [0.94254375 0.93959906 0.98055506 0.9410691  0.97017486]\n",
      " [0.96973791 0.93463542 0.99010163 0.95186315 0.97604751]\n",
      " [0.98807265 0.95443833 0.99611856 0.9709643  0.98561531]]\n",
      "Accuracy: 0.9538766083800726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.99      0.96      3859\n",
      "     Class 1       0.95      0.93      0.94      3775\n",
      "     Class 2       0.97      0.94      0.96      3858\n",
      "     Class 3       0.98      0.96      0.97      3663\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     15155\n",
      "   macro avg       0.96      0.96      0.96     15155\n",
      "weighted avg       0.96      0.96      0.96     15155\n",
      " samples avg       0.96      0.96      0.96     15155\n",
      "\n",
      "Precision:   [0.92803307 0.94853139 0.9703842  0.97823053]\n",
      "Sensitivity: [0.98911635 0.93245033 0.94271643 0.95686596]\n",
      "Specificity: [0.97379603 0.98321617 0.99017438 0.99321267]\n",
      "F1-score:    [0.95760161 0.94042212 0.95635025 0.96743031]\n",
      "Accuracy:    [0.97769713 0.97057077 0.97809304 0.98442758]\n",
      "\n",
      "[[0.92803307 0.98911635 0.97379603 0.95760161 0.97769713]\n",
      " [0.94853139 0.93245033 0.98321617 0.94042212 0.97057077]\n",
      " [0.9703842  0.94271643 0.99017438 0.95635025 0.97809304]\n",
      " [0.97823053 0.95686596 0.99321267 0.96743031 0.98442758]]\n",
      "95.39% (+/- 0.14%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "\n",
    "mean = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "std = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "for train, test in kfold.split (train_X, train_label):\n",
    "\n",
    "    intermediate_layer_model = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output = intermediate_layer_model.predict(train_X[train])\n",
    "\n",
    "    newArr = np.append(intermediate_output, XSCM[train] , axis=1)\n",
    "\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    #train_labels2=train_labels[:49984]\n",
    "    clf.fit(newArr,train_label[train])\n",
    "\n",
    "    intermediate_layer_model_2 = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output_2 = intermediate_layer_model_2.predict(train_X[test])\n",
    "\n",
    "    newArr_test = np.append(intermediate_output_2, XSCM[test] , axis=1)\n",
    "\n",
    "    y_pred=clf.predict(newArr_test)\n",
    "\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(train_label[test], y_pred))\n",
    "    cvscores.append(metrics.accuracy_score(train_label[test], y_pred)*100)\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "\n",
    "    predicted_classes = y_pred\n",
    "\n",
    "    predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "\n",
    "    predicted_classes = to_categorical(predicted_classes)\n",
    "\n",
    "    \n",
    "    num_classes = 4\n",
    "    from sklearn.metrics import classification_report\n",
    "    target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "    print(classification_report(train_label[test], predicted_classes, target_names=target_names))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    #converte os arrays de classe de one-hot para númerico\n",
    "    test_label_aux = np.argmax(train_label[test], axis=1)\n",
    "    predicted_classes = np.argmax(predicted_classes, axis=1)\n",
    "\n",
    "    #gera a matriz de confusão a partir da predição feita\n",
    "    cm = confusion_matrix(test_label_aux, predicted_classes)\n",
    "\n",
    "    #gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "    #gera a sensitividade, especificidade, acurácia e precisão\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision   = tp / (tp + fp)\n",
    "    f1_score = 2/((1/precision)+(1/sensitivity))\n",
    "\n",
    "    #mostra os resultados\n",
    "    print(\"Precision:  \", precision)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"F1-score:   \", f1_score)\n",
    "    print(\"Accuracy:   \", accuracy)\n",
    "    \n",
    "    x = []\n",
    "    x.append(precision)\n",
    "    x.append(sensitivity)\n",
    "    x.append(specificity)\n",
    "    x.append(f1_score)\n",
    "    x.append(accuracy)\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    x = x.transpose()\n",
    "    print()\n",
    "    print(x)\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            mean[i][j].append(x[i][j])\n",
    "            std[i][j].append(x[i][j])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores),np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dfad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92645239 0.99085932 0.97380324 0.95757104 0.97806693]\n",
      "[0.94505217 0.93924258 0.98178631 0.94213108 0.97115181]\n",
      "[0.97045004 0.93838958 0.99048143 0.95414699 0.97745987]\n",
      "[0.9841235  0.95436709 0.99488452 0.9690103  0.98474452]\n",
      "\n",
      "[0.00376701 0.00138453 0.0008643  0.00241466 0.00093949]\n",
      "[0.00283288 0.00416427 0.00113181 0.00241469 0.00128471]\n",
      "[0.00211877 0.00366183 0.00061582 0.00240205 0.00109847]\n",
      "[0.00332623 0.00227853 0.00097604 0.00126847 0.00054924]\n"
     ]
    }
   ],
   "source": [
    "mean = np.asarray(mean)\n",
    "std = np.asarray(std)\n",
    "for i in mean:\n",
    "    print(np.mean(i,axis=1))\n",
    "print()\n",
    "for i in std:\n",
    "    print(np.std(i,axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
