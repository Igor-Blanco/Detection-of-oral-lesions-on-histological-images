{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ce2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4585489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b365fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"D:/Modelos/ResNet50_IC_copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92410b77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 24,638,852\n",
      "Trainable params: 24,585,732\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffc904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75776, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((75776, 32, 32, 3), (75776, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carrega os arrays de imagens e de classes\n",
    "train_X = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3.npy\")\n",
    "train_label = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataYOneHot_teste3.npy\")\n",
    "XSCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_SCM.npy\")\n",
    "#XGLCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_GLCM.npy\")\n",
    "#dataX = np.load(\"Image Arrays/displasiaGeneratedDataX.npy\")\n",
    "#dataY = np.load(\"Image Arrays/displasiaGeneratedDataY.npy\")\n",
    "\n",
    "#XSCM = np.append(XSCM,XGLCM,axis=1)\n",
    "\n",
    "print(XSCM.shape)\n",
    "\n",
    "#shape dos arrays\n",
    "#train_X.shape, train_label.shape\n",
    "#shape dos arrays\n",
    "train_X.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8858e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X, test_X, train_label, test_label = train_test_split(X, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_label, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X.shape, train_label.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038f4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X_SCM, test_X_SCM, train_label_SCM, test_label_SCM = train_test_split(XSCM, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X_SCM, valid_X_SCM, train_label_SCM, valid_label_SCM = train_test_split(train_X_SCM, train_label_SCM, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X_SCM.shape, train_label_SCM.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X_SCM.shape, test_label_SCM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d74f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9455001319609395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.99      0.95      3867\n",
      "     Class 1       0.92      0.93      0.93      3755\n",
      "     Class 2       0.96      0.93      0.94      3686\n",
      "     Class 3       0.98      0.94      0.96      3848\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     15156\n",
      "   macro avg       0.95      0.95      0.95     15156\n",
      "weighted avg       0.95      0.95      0.95     15156\n",
      " samples avg       0.95      0.95      0.95     15156\n",
      "\n",
      "Precision:   [0.9243453  0.92495359 0.96040438 0.98189189]\n",
      "Sensitivity: [0.98577709 0.92889481 0.92783505 0.94412682]\n",
      "Specificity: [0.97236248 0.97517762 0.98770706 0.99407499]\n",
      "F1-score:    [0.95407333 0.92692001 0.94383883 0.96263911]\n",
      "Accuracy:    [0.97578517 0.96371074 0.97314595 0.98139351]\n",
      "\n",
      "[[0.9243453  0.98577709 0.97236248 0.95407333 0.97578517]\n",
      " [0.92495359 0.92889481 0.97517762 0.92692001 0.96371074]\n",
      " [0.96040438 0.92783505 0.98770706 0.94383883 0.97314595]\n",
      " [0.98189189 0.94412682 0.99407499 0.96263911 0.98139351]]\n",
      "Accuracy: 0.9447707027383702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.98      0.95      3761\n",
      "     Class 1       0.93      0.93      0.93      3776\n",
      "     Class 2       0.96      0.93      0.94      3819\n",
      "     Class 3       0.98      0.94      0.96      3799\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     15155\n",
      "   macro avg       0.95      0.95      0.95     15155\n",
      "weighted avg       0.95      0.95      0.95     15155\n",
      " samples avg       0.95      0.95      0.95     15155\n",
      "\n",
      "Precision:   [0.92246323 0.92832675 0.96248981 0.97765668]\n",
      "Sensitivity: [0.98378091 0.93299788 0.92720607 0.94445907]\n",
      "Specificity: [0.97270493 0.97609632 0.98782639 0.99277915]\n",
      "F1-score:    [0.95213587 0.93065645 0.94451854 0.96077119]\n",
      "Accuracy:    [0.97545365 0.96535797 0.97255031 0.98066645]\n",
      "\n",
      "[[0.92246323 0.98378091 0.97270493 0.95213587 0.97545365]\n",
      " [0.92832675 0.93299788 0.97609632 0.93065645 0.96535797]\n",
      " [0.96248981 0.92720607 0.98782639 0.94451854 0.97255031]\n",
      " [0.97765668 0.94445907 0.99277915 0.96077119 0.98066645]]\n",
      "Accuracy: 0.9408116133289344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.98      0.95      3802\n",
      "     Class 1       0.92      0.92      0.92      3797\n",
      "     Class 2       0.95      0.93      0.94      3741\n",
      "     Class 3       0.97      0.95      0.96      3815\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     15155\n",
      "   macro avg       0.94      0.94      0.94     15155\n",
      "weighted avg       0.94      0.94      0.94     15155\n",
      " samples avg       0.94      0.94      0.94     15155\n",
      "\n",
      "Precision:   [0.92511778 0.92254824 0.9545204  0.97359202]\n",
      "Sensitivity: [0.98132562 0.91914669 0.92568832 0.94705111]\n",
      "Specificity: [0.9733991  0.9742032  0.98554407 0.99135802]\n",
      "F1-score:    [0.95239311 0.92084433 0.93988329 0.96013819]\n",
      "Accuracy:    [0.97538766 0.96040911 0.97076872 0.98020455]\n",
      "\n",
      "[[0.92511778 0.98132562 0.9733991  0.95239311 0.97538766]\n",
      " [0.92254824 0.91914669 0.9742032  0.92084433 0.96040911]\n",
      " [0.9545204  0.92568832 0.98554407 0.93988329 0.97076872]\n",
      " [0.97359202 0.94705111 0.99135802 0.96013819 0.98020455]]\n",
      "Accuracy: 0.9435829759155394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.98      0.95      3655\n",
      "     Class 1       0.92      0.93      0.93      3841\n",
      "     Class 2       0.96      0.92      0.94      3840\n",
      "     Class 3       0.98      0.95      0.96      3819\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     15155\n",
      "   macro avg       0.95      0.95      0.94     15155\n",
      "weighted avg       0.95      0.94      0.94     15155\n",
      " samples avg       0.94      0.94      0.94     15155\n",
      "\n",
      "Precision:   [0.91931352 0.92492881 0.95577131 0.98152174]\n",
      "Sensitivity: [0.98194254 0.9302265  0.92291667 0.94579733]\n",
      "Specificity: [0.9726087  0.97436804 0.98550597 0.99400141]\n",
      "F1-score:    [0.94959651 0.92757009 0.9390567  0.96332844]\n",
      "Accuracy:    [0.97485978 0.96318047 0.96964698 0.98185417]\n",
      "\n",
      "[[0.91931352 0.98194254 0.9726087  0.94959651 0.97485978]\n",
      " [0.92492881 0.9302265  0.97436804 0.92757009 0.96318047]\n",
      " [0.95577131 0.92291667 0.98550597 0.9390567  0.96964698]\n",
      " [0.98152174 0.94579733 0.99400141 0.96332844 0.98185417]]\n",
      "Accuracy: 0.9423952490927087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.98      0.95      3859\n",
      "     Class 1       0.93      0.92      0.92      3775\n",
      "     Class 2       0.96      0.93      0.95      3858\n",
      "     Class 3       0.97      0.95      0.96      3663\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     15155\n",
      "   macro avg       0.94      0.94      0.94     15155\n",
      "weighted avg       0.94      0.94      0.94     15155\n",
      " samples avg       0.94      0.94      0.94     15155\n",
      "\n",
      "Precision:   [0.91899103 0.92801713 0.96240602 0.97031644]\n",
      "Sensitivity: [0.98186059 0.9186755  0.92897875 0.94594595]\n",
      "Specificity: [0.97043201 0.97636204 0.98760733 0.99077619]\n",
      "F1-score:    [0.94938612 0.92332268 0.94539699 0.95797622]\n",
      "Accuracy:    [0.97334213 0.96199274 0.97268228 0.97994061]\n",
      "\n",
      "[[0.91899103 0.98186059 0.97043201 0.94938612 0.97334213]\n",
      " [0.92801713 0.9186755  0.97636204 0.92332268 0.96199274]\n",
      " [0.96240602 0.92897875 0.98760733 0.94539699 0.97268228]\n",
      " [0.97031644 0.94594595 0.99077619 0.95797622 0.97994061]]\n",
      "94.34% (+/- 0.17%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "\n",
    "mean = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "std = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "for train, test in kfold.split (train_X, train_label):\n",
    "\n",
    "    intermediate_layer_model = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output = intermediate_layer_model.predict(train_X[train])\n",
    "\n",
    "    newArr = np.append(intermediate_output, XSCM[train] , axis=1)\n",
    "\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    #train_labels2=train_labels[:49984]\n",
    "    clf.fit(newArr,train_label[train])\n",
    "\n",
    "    intermediate_layer_model_2 = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output_2 = intermediate_layer_model_2.predict(train_X[test])\n",
    "\n",
    "    newArr_test = np.append(intermediate_output_2, XSCM[test] , axis=1)\n",
    "\n",
    "    y_pred=clf.predict(newArr_test)\n",
    "\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(train_label[test], y_pred))\n",
    "    cvscores.append(metrics.accuracy_score(train_label[test], y_pred)*100)\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "\n",
    "    predicted_classes = y_pred\n",
    "\n",
    "    predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "\n",
    "    predicted_classes = to_categorical(predicted_classes)\n",
    "\n",
    "    \n",
    "    num_classes = 4\n",
    "    from sklearn.metrics import classification_report\n",
    "    target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "    print(classification_report(train_label[test], predicted_classes, target_names=target_names))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    #converte os arrays de classe de one-hot para númerico\n",
    "    test_label_aux = np.argmax(train_label[test], axis=1)\n",
    "    predicted_classes = np.argmax(predicted_classes, axis=1)\n",
    "\n",
    "    #gera a matriz de confusão a partir da predição feita\n",
    "    cm = confusion_matrix(test_label_aux, predicted_classes)\n",
    "\n",
    "    #gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "    #gera a sensitividade, especificidade, acurácia e precisão\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision   = tp / (tp + fp)\n",
    "    f1_score = 2/((1/precision)+(1/sensitivity))\n",
    "\n",
    "    #mostra os resultados\n",
    "    print(\"Precision:  \", precision)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"F1-score:   \", f1_score)\n",
    "    print(\"Accuracy:   \", accuracy)\n",
    "    \n",
    "    x = []\n",
    "    x.append(precision)\n",
    "    x.append(sensitivity)\n",
    "    x.append(specificity)\n",
    "    x.append(f1_score)\n",
    "    x.append(accuracy)\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    x = x.transpose()\n",
    "    print()\n",
    "    print(x)\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            mean[i][j].append(x[i][j])\n",
    "            std[i][j].append(x[i][j])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores),np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dfad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92204617 0.98293735 0.97230144 0.95151699 0.97496568]\n",
      "[0.9257549  0.92598828 0.97524144 0.92586271 0.96293021]\n",
      "[0.95911838 0.92652497 0.98683816 0.94253887 0.97175885]\n",
      "[0.97699575 0.94547606 0.99259795 0.96097063 0.98081186]\n",
      "\n",
      "[0.00251777 0.00164453 0.00099605 0.00178406 0.00086428]\n",
      "[0.00216052 0.00593008 0.00087537 0.00342488 0.00166137]\n",
      "[0.00335181 0.00209385 0.00107449 0.00256731 0.00132993]\n",
      "[0.00449649 0.00106391 0.00134465 0.0018996  0.00071746]\n"
     ]
    }
   ],
   "source": [
    "mean = np.asarray(mean)\n",
    "std = np.asarray(std)\n",
    "for i in mean:\n",
    "    print(np.mean(i,axis=1))\n",
    "print()\n",
    "for i in std:\n",
    "    print(np.std(i,axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
