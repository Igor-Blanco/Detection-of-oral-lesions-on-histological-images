{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ce2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4585489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b365fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_215623) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_254805) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_257010) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_254845) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_253233) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_215297) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_216487) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_262359) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_214684) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_254666) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_218297) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_261806) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_218742) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_262952) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_217879) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_217747) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_260234) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_254292) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_216313) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_217308) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_216445) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_se_reduce_layer_call_and_return_conditional_losses_218165) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_se_reduce_layer_call_and_return_conditional_losses_253786) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_256417) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_se_reduce_layer_call_and_return_conditional_losses_258069) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_252880) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_255219) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_215414) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_255864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_214801) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_261300) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_215875) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_261161) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_214295) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_264058) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_256457) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_260194) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_216069) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_257337) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_activation_layer_call_and_return_conditional_losses_215665) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_218130) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_244127) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_216654) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_216104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_216278) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_se_reduce_layer_call_and_return_conditional_losses_214474) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_217343) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_264385) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_se_reduce_layer_call_and_return_conditional_losses_218583) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_activation_layer_call_and_return_conditional_losses_217921) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_215491) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_expand_activation_layer_call_and_return_conditional_losses_256278) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_expand_activation_layer_call_and_return_conditional_losses_216027) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_216848) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_253746) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_activation_layer_call_and_return_conditional_losses_215456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_expand_activation_layer_call_and_return_conditional_losses_258996) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_215262) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_activation_layer_call_and_return_conditional_losses_217712) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_217670) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_expand_activation_layer_call_and_return_conditional_losses_258443) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb1_layer_call_and_return_conditional_losses_248195) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_activation_layer_call_and_return_conditional_losses_256970) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_216522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_expand_activation_layer_call_and_return_conditional_losses_262220) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_216731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_254252) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_se_reduce_layer_call_and_return_conditional_losses_257516) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_expand_activation_layer_call_and_return_conditional_losses_254113) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_241574) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_se_reduce_layer_call_and_return_conditional_losses_255398) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_activation_layer_call_and_return_conditional_losses_255358) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_expand_activation_layer_call_and_return_conditional_losses_218700) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_214253) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_expand_activation_layer_call_and_return_conditional_losses_255725) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_260608) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_218548) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_se_reduce_layer_call_and_return_conditional_losses_214878) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_263505) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_262399) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_216925) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_expand_activation_layer_call_and_return_conditional_losses_215010) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_216696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_expand_activation_layer_call_and_return_conditional_losses_217266) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_se_reduce_layer_call_and_return_conditional_losses_217134) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_expand_activation_layer_call_and_return_conditional_losses_261667) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block5c_activation_layer_call_and_return_conditional_losses_217099) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_activation_layer_call_and_return_conditional_losses_259135) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_216236) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_214606) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_215832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_expand_activation_layer_call_and_return_conditional_losses_253607) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_activation_layer_call_and_return_conditional_losses_260747) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_stem_activation_layer_call_and_return_conditional_losses_252701) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_expand_activation_layer_call_and_return_conditional_losses_217475) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_expand_activation_layer_call_and_return_conditional_losses_263326) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_activation_layer_call_and_return_conditional_losses_258582) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6b_se_reduce_layer_call_and_return_conditional_losses_261846) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3b_se_reduce_layer_call_and_return_conditional_losses_255904) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_se_reduce_layer_call_and_return_conditional_losses_215910) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_expand_activation_layer_call_and_return_conditional_losses_257890) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_264564) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_262773) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_se_reduce_layer_call_and_return_conditional_losses_218374) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_activation_layer_call_and_return_conditional_losses_215052) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_217057) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2a_activation_layer_call_and_return_conditional_losses_214649) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5c_expand_activation_layer_call_and_return_conditional_losses_260055) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_se_reduce_layer_call_and_return_conditional_losses_259681) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_activation_layer_call_and_return_conditional_losses_252840) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_activation_layer_call_and_return_conditional_losses_264018) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5a_se_reduce_layer_call_and_return_conditional_losses_259175) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2b_activation_layer_call_and_return_conditional_losses_214843) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6d_activation_layer_call_and_return_conditional_losses_262912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_263879) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_efficientnetb1_layer_call_and_return_conditional_losses_250729) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6c_se_reduce_layer_call_and_return_conditional_losses_217956) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_218909) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4d_se_reduce_layer_call_and_return_conditional_losses_258622) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1a_se_reduce_layer_call_and_return_conditional_losses_214330) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7a_expand_activation_layer_call_and_return_conditional_losses_218506) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_top_activation_layer_call_and_return_conditional_losses_264938) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_259641) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block2c_se_reduce_layer_call_and_return_conditional_losses_215087) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5d_se_reduce_layer_call_and_return_conditional_losses_260787) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4a_expand_activation_layer_call_and_return_conditional_losses_256831) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_204708) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_activation_layer_call_and_return_conditional_losses_217518) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_261340) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_block6d_expand_activation_layer_call_and_return_conditional_losses_218088) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_263465) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_214439) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4c_activation_layer_call_and_return_conditional_losses_258029) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block1b_activation_layer_call_and_return_conditional_losses_253193) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_expand_activation_layer_call_and_return_conditional_losses_259502) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6a_se_reduce_layer_call_and_return_conditional_losses_217553) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block4b_activation_layer_call_and_return_conditional_losses_257476) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block5b_activation_layer_call_and_return_conditional_losses_216890) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_activation_layer_call_and_return_conditional_losses_264524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3a_expand_activation_layer_call_and_return_conditional_losses_215219) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block7b_se_reduce_layer_call_and_return_conditional_losses_218777) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block6e_activation_layer_call_and_return_conditional_losses_218339) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_block3c_se_reduce_layer_call_and_return_conditional_losses_215700) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"D:/Modelos/EfficientNet_B1_IMAGENET_IC_SCM3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92410b77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb1 (Functional)  (None, 1, 1, 1280)        6575239   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 5124      \n",
      "=================================================================\n",
      "Total params: 6,580,363\n",
      "Trainable params: 6,518,308\n",
      "Non-trainable params: 62,055\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffc904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75776, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((75776, 32, 32, 3), (75776, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carrega os arrays de imagens e de classes\n",
    "train_X = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3.npy\")\n",
    "train_label = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataYOneHot_teste3.npy\")\n",
    "XSCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_SCM.npy\")\n",
    "XGLCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_GLCM.npy\")\n",
    "#dataX = np.load(\"Image Arrays/displasiaGeneratedDataX.npy\")\n",
    "#dataY = np.load(\"Image Arrays/displasiaGeneratedDataY.npy\")\n",
    "\n",
    "XSCM = np.append(XSCM,XGLCM,axis=1)\n",
    "\n",
    "print(XSCM.shape)\n",
    "\n",
    "#shape dos arrays\n",
    "#train_X.shape, train_label.shape\n",
    "#shape dos arrays\n",
    "train_X.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8858e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X, test_X, train_label, test_label = train_test_split(X, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_label, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X.shape, train_label.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038f4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X_SCM, test_X_SCM, train_label_SCM, test_label_SCM = train_test_split(XSCM, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X_SCM, valid_X_SCM, train_label_SCM, valid_label_SCM = train_test_split(train_X_SCM, train_label_SCM, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X_SCM.shape, train_label_SCM.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X_SCM.shape, test_label_SCM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d74f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9984164687252574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3867\n",
      "     Class 1       1.00      1.00      1.00      3755\n",
      "     Class 2       1.00      1.00      1.00      3686\n",
      "     Class 3       1.00      1.00      1.00      3848\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15156\n",
      "   macro avg       1.00      1.00      1.00     15156\n",
      "weighted avg       1.00      1.00      1.00     15156\n",
      " samples avg       1.00      1.00      1.00     15156\n",
      "\n",
      "Precision:   [0.99974147 0.99680596 0.99728703 0.99973992]\n",
      "Sensitivity: [1.         0.99733688 0.99728703 0.9989605 ]\n",
      "Specificity: [0.99991142 0.99894746 0.99912816 0.99991157]\n",
      "F1-score:    [0.99987072 0.99707135 0.99728703 0.99935006]\n",
      "Accuracy:    [0.99993402 0.99854843 0.99868039 0.9996701 ]\n",
      "\n",
      "[[0.99974147 1.         0.99991142 0.99987072 0.99993402]\n",
      " [0.99680596 0.99733688 0.99894746 0.99707135 0.99854843]\n",
      " [0.99728703 0.99728703 0.99912816 0.99728703 0.99868039]\n",
      " [0.99973992 0.9989605  0.99991157 0.99935006 0.9996701 ]]\n",
      "Accuracy: 0.9984163642362257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3761\n",
      "     Class 1       1.00      1.00      1.00      3776\n",
      "     Class 2       1.00      1.00      1.00      3819\n",
      "     Class 3       1.00      1.00      1.00      3799\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [0.9989373  0.99867268 0.99686438 0.9992099 ]\n",
      "Sensitivity: [0.99973411 0.99629237 0.99895261 0.99868386]\n",
      "Specificity: [0.99964894 0.99956059 0.99894143 0.99973582]\n",
      "F1-score:    [0.99933555 0.99748111 0.9979074  0.99894681]\n",
      "Accuracy:    [0.99967008 0.99874629 0.99894424 0.99947212]\n",
      "\n",
      "[[0.9989373  0.99973411 0.99964894 0.99933555 0.99967008]\n",
      " [0.99867268 0.99629237 0.99956059 0.99748111 0.99874629]\n",
      " [0.99686438 0.99895261 0.99894143 0.9979074  0.99894424]\n",
      " [0.9992099  0.99868386 0.99973582 0.99894681 0.99947212]]\n",
      "Accuracy: 0.9981524249422633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3802\n",
      "     Class 1       1.00      1.00      1.00      3797\n",
      "     Class 2       1.00      1.00      1.00      3741\n",
      "     Class 3       1.00      1.00      1.00      3815\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [1.         0.99631482 0.99706118 0.99921301]\n",
      "Sensitivity: [0.99973698 0.99683961 0.99759423 0.99842726]\n",
      "Specificity: [1.         0.99876739 0.99903627 0.99973545]\n",
      "F1-score:    [0.99986847 0.99657715 0.99732763 0.99881998]\n",
      "Accuracy:    [0.99993402 0.99828439 0.9986803  0.99940614]\n",
      "\n",
      "[[1.         0.99973698 1.         0.99986847 0.99993402]\n",
      " [0.99631482 0.99683961 0.99876739 0.99657715 0.99828439]\n",
      " [0.99706118 0.99759423 0.99903627 0.99732763 0.9986803 ]\n",
      " [0.99921301 0.99842726 0.99973545 0.99881998 0.99940614]]\n",
      "Accuracy: 0.9978884856483009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3655\n",
      "     Class 1       1.00      1.00      1.00      3841\n",
      "     Class 2       1.00      1.00      1.00      3840\n",
      "     Class 3       1.00      1.00      1.00      3819\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [0.9994528  0.99635512 0.99687744 0.99895178]\n",
      "Sensitivity: [0.9994528  0.99635512 0.99765625 0.99816706]\n",
      "Specificity: [0.99982609 0.9987626  0.99893946 0.99964714]\n",
      "F1-score:    [0.9994528  0.99635512 0.99726669 0.99855927]\n",
      "Accuracy:    [0.99973606 0.99815242 0.99861432 0.99927417]\n",
      "\n",
      "[[0.9994528  0.9994528  0.99982609 0.9994528  0.99973606]\n",
      " [0.99635512 0.99635512 0.9987626  0.99635512 0.99815242]\n",
      " [0.99687744 0.99765625 0.99893946 0.99726669 0.99861432]\n",
      " [0.99895178 0.99816706 0.99964714 0.99855927 0.99927417]]\n",
      "Accuracy: 0.9981524249422633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00      3859\n",
      "     Class 1       1.00      1.00      1.00      3775\n",
      "     Class 2       1.00      1.00      1.00      3858\n",
      "     Class 3       1.00      1.00      1.00      3663\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     15155\n",
      "   macro avg       1.00      1.00      1.00     15155\n",
      "weighted avg       1.00      1.00      1.00     15155\n",
      " samples avg       1.00      1.00      1.00     15155\n",
      "\n",
      "Precision:   [0.99974093 0.99629434 0.99818418 0.99863463]\n",
      "Sensitivity: [1.         0.99708609 0.99740798 0.998362  ]\n",
      "Specificity: [0.99991147 0.99876977 0.99938037 0.99956491]\n",
      "F1-score:    [0.99987045 0.99669006 0.99779593 0.99849829]\n",
      "Accuracy:    [0.99993402 0.99835038 0.99887826 0.99927417]\n",
      "\n",
      "[[0.99974093 1.         0.99991147 0.99987045 0.99993402]\n",
      " [0.99629434 0.99708609 0.99876977 0.99669006 0.99835038]\n",
      " [0.99818418 0.99740798 0.99938037 0.99779593 0.99887826]\n",
      " [0.99863463 0.998362   0.99956491 0.99849829 0.99927417]]\n",
      "99.82% (+/- 0.02%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "\n",
    "mean = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "std = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "\n",
    "for train, test in kfold.split (train_X, train_label):\n",
    "\n",
    "    intermediate_layer_model = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output = intermediate_layer_model.predict(train_X[train])\n",
    "\n",
    "    newArr = np.append(intermediate_output, XSCM[train] , axis=1)\n",
    "\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    #train_labels2=train_labels[:49984]\n",
    "    clf.fit(newArr,train_label[train])\n",
    "\n",
    "    intermediate_layer_model_2 = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output_2 = intermediate_layer_model_2.predict(train_X[test])\n",
    "\n",
    "    newArr_test = np.append(intermediate_output_2, XSCM[test] , axis=1)\n",
    "\n",
    "    y_pred=clf.predict(newArr_test)\n",
    "\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(train_label[test], y_pred))\n",
    "    cvscores.append(metrics.accuracy_score(train_label[test], y_pred)*100)\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "\n",
    "    predicted_classes = y_pred\n",
    "\n",
    "    predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "\n",
    "    predicted_classes = to_categorical(predicted_classes)\n",
    "\n",
    "    \n",
    "    num_classes = 4\n",
    "    from sklearn.metrics import classification_report\n",
    "    target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "    print(classification_report(train_label[test], predicted_classes, target_names=target_names))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    #converte os arrays de classe de one-hot para númerico\n",
    "    test_label_aux = np.argmax(train_label[test], axis=1)\n",
    "    predicted_classes = np.argmax(predicted_classes, axis=1)\n",
    "\n",
    "    #gera a matriz de confusão a partir da predição feita\n",
    "    cm = confusion_matrix(test_label_aux, predicted_classes)\n",
    "\n",
    "    #gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "    #gera a sensitividade, especificidade, acurácia e precisão\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision   = tp / (tp + fp)\n",
    "    f1_score = 2/((1/precision)+(1/sensitivity))\n",
    "\n",
    "    #mostra os resultados\n",
    "    print(\"Precision:  \", precision)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"F1-score:   \", f1_score)\n",
    "    print(\"Accuracy:   \", accuracy)\n",
    "    \n",
    "    x = []\n",
    "    x.append(precision)\n",
    "    x.append(sensitivity)\n",
    "    x.append(specificity)\n",
    "    x.append(f1_score)\n",
    "    x.append(accuracy)\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    x = x.transpose()\n",
    "    print()\n",
    "    print(x)\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            mean[i][j].append(x[i][j])\n",
    "            std[i][j].append(x[i][j])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores),np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dfad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9995745  0.99978478 0.99985958 0.9996796  0.99984164]\n",
      "[0.99688858 0.99678202 0.99896156 0.99683496 0.99841638]\n",
      "[0.99725484 0.99777962 0.99908514 0.99751694 0.9987595 ]\n",
      "[0.99914985 0.99852014 0.99971898 0.99883488 0.99941934]\n",
      "\n",
      "[0.00036262 0.00020381 0.00011882 0.00023598 0.00011505]\n",
      "[0.00091179 0.00040636 0.00030761 0.00039777 0.00020867]\n",
      "[0.0004893  0.00060104 0.00016326 0.00027627 0.00012794]\n",
      "[0.00036345 0.00027533 0.00011536 0.00030575 0.00014696]\n"
     ]
    }
   ],
   "source": [
    "mean = np.asarray(mean)\n",
    "std = np.asarray(std)\n",
    "for i in mean:\n",
    "    print(np.mean(i,axis=1))\n",
    "print()\n",
    "for i in std:\n",
    "    print(np.std(i,axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
