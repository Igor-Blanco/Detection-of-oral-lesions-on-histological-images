{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884ce2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4585489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b365fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"D:/Modelos/ResNet50_IC_copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92410b77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 24,638,852\n",
      "Trainable params: 24,585,732\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fffc904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75776, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((75776, 32, 32, 3), (75776, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carrega os arrays de imagens e de classes\n",
    "train_X = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3.npy\")\n",
    "train_label = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataYOneHot_teste3.npy\")\n",
    "XSCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_SCM.npy\")\n",
    "XGLCM = np.load(\"D:/Displasia/displasiaDataAug/displasiaOriginalDataX_teste3_GLCM.npy\")\n",
    "#dataX = np.load(\"Image Arrays/displasiaGeneratedDataX.npy\")\n",
    "#dataY = np.load(\"Image Arrays/displasiaGeneratedDataY.npy\")\n",
    "\n",
    "XSCM = np.append(XSCM,XGLCM,axis=1)\n",
    "\n",
    "print(XSCM.shape)\n",
    "\n",
    "#shape dos arrays\n",
    "#train_X.shape, train_label.shape\n",
    "#shape dos arrays\n",
    "train_X.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8858e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X, test_X, train_label, test_label = train_test_split(X, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X, valid_X, train_label, valid_label = train_test_split(train_X, train_label, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X.shape, train_label.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038f4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide os dados em 80% para treino e 20% para teste\n",
    "#train_X_SCM, test_X_SCM, train_label_SCM, test_label_SCM = train_test_split(XSCM, Y, test_size=0.2, random_state=13)\n",
    "\n",
    "#divide os dados de treino em 80% para treino e 20% para validação\n",
    "#train_X_SCM, valid_X_SCM, train_label_SCM, valid_label_SCM = train_test_split(train_X_SCM, train_label_SCM, test_size=0.2, random_state=13)\n",
    "\n",
    "#mostra os shapes resultantes das divisões\n",
    "#print(\"Training:   \", train_X_SCM.shape, train_label_SCM.shape)\n",
    "#print(\"Validation: \", valid_X.shape, valid_label.shape)\n",
    "#print(\"Testing:    \", test_X_SCM.shape, test_label_SCM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d74f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953351807864872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.99      0.96      3867\n",
      "     Class 1       0.94      0.94      0.94      3755\n",
      "     Class 2       0.97      0.94      0.95      3686\n",
      "     Class 3       0.99      0.95      0.97      3848\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     15156\n",
      "   macro avg       0.96      0.95      0.96     15156\n",
      "weighted avg       0.96      0.96      0.96     15156\n",
      " samples avg       0.96      0.96      0.96     15156\n",
      "\n",
      "Precision:   [0.92722437 0.94180459 0.96838276 0.98702703]\n",
      "Sensitivity: [0.99172485 0.93954727 0.93895822 0.94906445]\n",
      "Specificity: [0.97333688 0.98087887 0.99014821 0.99575522]\n",
      "F1-score:    [0.9583906  0.94067458 0.95344353 0.96767356]\n",
      "Accuracy:    [0.9780285  0.97063869 0.9776986  0.98390077]\n",
      "\n",
      "[[0.92722437 0.99172485 0.97333688 0.9583906  0.9780285 ]\n",
      " [0.94180459 0.93954727 0.98087887 0.94067458 0.97063869]\n",
      " [0.96838276 0.93895822 0.99014821 0.95344353 0.9776986 ]\n",
      " [0.98702703 0.94906445 0.99575522 0.96767356 0.98390077]]\n",
      "Accuracy: 0.9544704717914879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.99      0.96      3761\n",
      "     Class 1       0.95      0.94      0.95      3776\n",
      "     Class 2       0.97      0.94      0.95      3819\n",
      "     Class 3       0.99      0.95      0.97      3799\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     15155\n",
      "   macro avg       0.96      0.96      0.96     15155\n",
      "weighted avg       0.96      0.96      0.96     15155\n",
      " samples avg       0.96      0.96      0.96     15155\n",
      "\n",
      "Precision:   [0.92277228 0.94890899 0.97229766 0.98639456]\n",
      "Sensitivity: [0.99122574 0.94438559 0.93741817 0.95419847]\n",
      "Specificity: [0.97261717 0.98312681 0.99100212 0.99559704]\n",
      "F1-score:    [0.9557749  0.94664189 0.95453939 0.97002944]\n",
      "Accuracy:    [0.97723524 0.9734741  0.97749918 0.9852194 ]\n",
      "\n",
      "[[0.92277228 0.99122574 0.97261717 0.9557749  0.97723524]\n",
      " [0.94890899 0.94438559 0.98312681 0.94664189 0.9734741 ]\n",
      " [0.97229766 0.93741817 0.99100212 0.95453939 0.97749918]\n",
      " [0.98639456 0.95419847 0.99559704 0.97002944 0.9852194 ]]\n",
      "Accuracy: 0.9511712306169581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.93      0.99      0.96      3802\n",
      "     Class 1       0.94      0.94      0.94      3797\n",
      "     Class 2       0.97      0.93      0.95      3741\n",
      "     Class 3       0.98      0.96      0.97      3815\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     15155\n",
      "   macro avg       0.95      0.95      0.95     15155\n",
      "weighted avg       0.95      0.95      0.95     15155\n",
      " samples avg       0.95      0.95      0.95     15155\n",
      "\n",
      "Precision:   [0.92644526 0.94194062 0.96775987 0.98172043]\n",
      "Sensitivity: [0.9905313  0.93573874 0.93076717 0.95727392]\n",
      "Specificity: [0.97366335 0.98071844 0.98983704 0.99400353]\n",
      "F1-score:    [0.95741706 0.93882944 0.94890312 0.96934307]\n",
      "Accuracy:    [0.97789508 0.96944903 0.97525569 0.98475751]\n",
      "\n",
      "[[0.92644526 0.9905313  0.97366335 0.95741706 0.97789508]\n",
      " [0.94194062 0.93573874 0.98071844 0.93882944 0.96944903]\n",
      " [0.96775987 0.93076717 0.98983704 0.94890312 0.97525569]\n",
      " [0.98172043 0.95727392 0.99400353 0.96934307 0.98475751]]\n",
      "Accuracy: 0.9511712306169581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.99      0.96      3655\n",
      "     Class 1       0.94      0.94      0.94      3841\n",
      "     Class 2       0.97      0.93      0.95      3840\n",
      "     Class 3       0.99      0.95      0.97      3819\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     15155\n",
      "   macro avg       0.95      0.95      0.95     15155\n",
      "weighted avg       0.95      0.95      0.95     15155\n",
      " samples avg       0.95      0.95      0.95     15155\n",
      "\n",
      "Precision:   [0.92295918 0.93875424 0.96500673 0.98913929]\n",
      "Sensitivity: [0.98987688 0.93777662 0.93359375 0.95391464]\n",
      "Specificity: [0.97373913 0.97922927 0.98851083 0.99647142]\n",
      "F1-score:    [0.95524752 0.93826517 0.94904037 0.97120768]\n",
      "Accuracy:    [0.97763114 0.96872319 0.97459584 0.98574728]\n",
      "\n",
      "[[0.92295918 0.98987688 0.97373913 0.95524752 0.97763114]\n",
      " [0.93875424 0.93777662 0.97922927 0.93826517 0.96872319]\n",
      " [0.96500673 0.93359375 0.98851083 0.94904037 0.97459584]\n",
      " [0.98913929 0.95391464 0.99647142 0.97120768 0.98574728]]\n",
      "Accuracy: 0.9522269877928077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.92      0.99      0.96      3859\n",
      "     Class 1       0.95      0.93      0.94      3775\n",
      "     Class 2       0.97      0.94      0.96      3858\n",
      "     Class 3       0.98      0.95      0.97      3663\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     15155\n",
      "   macro avg       0.96      0.95      0.95     15155\n",
      "weighted avg       0.95      0.95      0.95     15155\n",
      " samples avg       0.95      0.95      0.95     15155\n",
      "\n",
      "Precision:   [0.92248249 0.94765246 0.97058824 0.97982063]\n",
      "Sensitivity: [0.98989375 0.93033113 0.94090202 0.95440895]\n",
      "Specificity: [0.97158286 0.98295255 0.9902629  0.99373477]\n",
      "F1-score:    [0.955      0.93891191 0.95551461 0.96694786]\n",
      "Accuracy:    [0.97624546 0.96984494 0.97769713 0.98422963]\n",
      "\n",
      "[[0.92248249 0.98989375 0.97158286 0.955      0.97624546]\n",
      " [0.94765246 0.93033113 0.98295255 0.93891191 0.96984494]\n",
      " [0.97058824 0.94090202 0.9902629  0.95551461 0.97769713]\n",
      " [0.97982063 0.95440895 0.99373477 0.96694786 0.98422963]]\n",
      "95.25% (+/- 0.13%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from sklearn.model_selection import KFold\n",
    "#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "cvscores = []\n",
    "\n",
    "mean = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "std = [[[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]],\n",
    "         [[],[],[],[],[]]]\n",
    "\n",
    "for train, test in kfold.split (train_X, train_label):\n",
    "\n",
    "    intermediate_layer_model = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output = intermediate_layer_model.predict(train_X[train])\n",
    "\n",
    "    newArr = np.append(intermediate_output, XSCM[train] , axis=1)\n",
    "\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "    #train_labels2=train_labels[:49984]\n",
    "    clf.fit(newArr,train_label[train])\n",
    "\n",
    "    intermediate_layer_model_2 = keras.Model(inputs=new_model.input,\n",
    "                                           outputs=new_model.get_layer('flatten').output)\n",
    "    intermediate_output_2 = intermediate_layer_model_2.predict(train_X[test])\n",
    "\n",
    "    newArr_test = np.append(intermediate_output_2, XSCM[test] , axis=1)\n",
    "\n",
    "    y_pred=clf.predict(newArr_test)\n",
    "\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(train_label[test], y_pred))\n",
    "    cvscores.append(metrics.accuracy_score(train_label[test], y_pred)*100)\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "\n",
    "    predicted_classes = y_pred\n",
    "\n",
    "    predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "\n",
    "    predicted_classes = to_categorical(predicted_classes)\n",
    "\n",
    "    \n",
    "    num_classes = 4\n",
    "    from sklearn.metrics import classification_report\n",
    "    target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "    print(classification_report(train_label[test], predicted_classes, target_names=target_names))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    #converte os arrays de classe de one-hot para númerico\n",
    "    test_label_aux = np.argmax(train_label[test], axis=1)\n",
    "    predicted_classes = np.argmax(predicted_classes, axis=1)\n",
    "\n",
    "    #gera a matriz de confusão a partir da predição feita\n",
    "    cm = confusion_matrix(test_label_aux, predicted_classes)\n",
    "\n",
    "    #gera os valores de falso positivo, falso negativo, verdadeiro positivo e verdadeiro negativo\n",
    "    fp = cm.sum(axis=0) - np.diag(cm)  \n",
    "    fn = cm.sum(axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tn = cm.sum() - (fp + fn + tp)\n",
    "\n",
    "    #gera a sensitividade, especificidade, acurácia e precisão\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy    = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision   = tp / (tp + fp)\n",
    "    f1_score = 2/((1/precision)+(1/sensitivity))\n",
    "\n",
    "    #mostra os resultados\n",
    "    print(\"Precision:  \", precision)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"F1-score:   \", f1_score)\n",
    "    print(\"Accuracy:   \", accuracy)\n",
    "    \n",
    "    x = []\n",
    "    x.append(precision)\n",
    "    x.append(sensitivity)\n",
    "    x.append(specificity)\n",
    "    x.append(f1_score)\n",
    "    x.append(accuracy)\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    x = x.transpose()\n",
    "    print()\n",
    "    print(x)\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            mean[i][j].append(x[i][j])\n",
    "            std[i][j].append(x[i][j])\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores),np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53dfad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92437672 0.9906505  0.97298788 0.95636602 0.97740709]\n",
      "[0.94381218 0.93755587 0.98138119 0.9406646  0.97042599]\n",
      "[0.96880705 0.93632787 0.98995222 0.9522882  0.97654929]\n",
      "[0.98482039 0.95377209 0.9951124  0.96904032 0.98477092]\n",
      "\n",
      "[0.00202779 0.00073082 0.00080671 0.00131682 0.00064084]\n",
      "[0.00384295 0.00460778 0.00147232 0.00309597 0.00164486]\n",
      "[0.00249303 0.00367225 0.00081586 0.00278638 0.00134388]\n",
      "[0.00348159 0.00264698 0.00106042 0.00155009 0.00066404]\n"
     ]
    }
   ],
   "source": [
    "mean = np.asarray(mean)\n",
    "std = np.asarray(std)\n",
    "for i in mean:\n",
    "    print(np.mean(i,axis=1))\n",
    "print()\n",
    "for i in std:\n",
    "    print(np.std(i,axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
